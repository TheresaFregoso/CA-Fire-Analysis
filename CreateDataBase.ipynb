{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a SQLite DataBase \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing database 'Outputs/DB/fire_data.sqlite' has been deleted.\n",
      "SQLite database saved to: Outputs/DB/fire_data.sqlite\n"
     ]
    }
   ],
   "source": [
    "import fiona\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "sqlite_db_path = 'Outputs/DB/fire_data.sqlite'\n",
    "\n",
    "# Check if the database exists\n",
    "if os.path.exists(sqlite_db_path):\n",
    "    # Delete the existing database\n",
    "    os.remove(sqlite_db_path)\n",
    "    print(f\"Existing database '{sqlite_db_path}' has been deleted.\")\n",
    "\n",
    "# Define the paths to the files\n",
    "gpkg_path = 'Resources/California_County_Boundaries.gpkg'\n",
    "fires_csv_path = 'Outputs/fire_stats_year_county.csv'\n",
    "extracted_csv_path = 'Outputs/extracted_data.csv'\n",
    "\n",
    "# Create a SQLite database connection\n",
    "conn = sqlite3.connect(sqlite_db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Load the CSV files into SQLite using pandas\n",
    "fires_df = pd.read_csv(fires_csv_path)\n",
    "extracted_df = pd.read_csv(extracted_csv_path)\n",
    "\n",
    "fires_df.to_sql('fires', conn, if_exists='replace', index=False)\n",
    "extracted_df.to_sql('extracted', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Use Fiona to read the GeoPackage and extract the attribute data\n",
    "with fiona.open(gpkg_path, layer=0) as layer:\n",
    "    # Read the records and their properties (attributes) into a DataFrame\n",
    "    records = [feature['properties'] for feature in layer]\n",
    "    gpkg_df = pd.DataFrame(records)\n",
    "\n",
    "# Load the extracted attribute data into SQLite\n",
    "gpkg_df.to_sql('california_county_boundaries', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Perform the JOIN operation with explicit column selection and renaming to avoid duplication\n",
    "final_query_with_explicit_columns = \"\"\"\n",
    "    SELECT ej.County as Extracted_County, ej.*, f.County as Fire_County, f.*\n",
    "    FROM (\n",
    "        SELECT e.*, g.*\n",
    "        FROM extracted e\n",
    "        JOIN california_county_boundaries g\n",
    "        ON e.County = g.COUNTY_NAME\n",
    "    ) ej\n",
    "    JOIN fires f\n",
    "    ON ej.County = f.County\n",
    "\"\"\"\n",
    "\n",
    "# Execute the final query\n",
    "final_df = pd.read_sql_query(final_query_with_explicit_columns, conn)\n",
    "\n",
    "# Remove the duplicated columns\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]\n",
    "\n",
    "# Save the final result to a new table\n",
    "final_df.to_sql('final_merged_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Provide the path to the SQLite database\n",
    "print(\"SQLite database saved to:\", sqlite_db_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      County  Year                      Fire Name\n",
      "0  San Mateo  2008                    Martin Fire\n",
      "1  San Mateo  2008                         Quarry\n",
      "2  San Mateo  2008                        Trabing\n",
      "3  San Mateo  2020  CZU AUGUST LIGHTNING\\nCOMPLEX\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check if the file exists\n",
    "sqlite_db_path = 'Outputs/DB/fire_data.sqlite'\n",
    "if os.path.exists(sqlite_db_path):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(sqlite_db_path)\n",
    "    \n",
    "    # Query to check for unique Fire Names in Alameda County\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        County,\n",
    "        Year,\n",
    "        \"Fire Name\"\n",
    "    FROM\n",
    "        fires\n",
    "    WHERE\n",
    "        County = 'San Mateo'\n",
    "    ORDER BY\n",
    "        Year, \"Fire Name\";\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and load the result into a DataFrame\n",
    "    alameda_fire_names_df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    \n",
    "    # Display the unique Fire Names for Alameda County by year\n",
    "    print(alameda_fire_names_df.head(20))  # Display the first 20 rows to inspect the data\n",
    "else:\n",
    "    print(\"The database file does not exist at the specified path:\", sqlite_db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      County  Year  Total_Fires\n",
      "0    Alameda  2010            1\n",
      "1    Alameda  2011            1\n",
      "2    Alameda  2015            1\n",
      "3    Alameda  2018            1\n",
      "4    Alameda  2022            1\n",
      "..       ...   ...          ...\n",
      "452     Yuba  2011            1\n",
      "453     Yuba  2016            1\n",
      "454     Yuba  2017            2\n",
      "455     Yuba  2020            3\n",
      "456     Yuba  2021            1\n",
      "\n",
      "[457 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your SQLite database\n",
    "sqlite_db_path = 'Outputs/DB/fire_data.sqlite'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    County,\n",
    "    Year,\n",
    "    COUNT(DISTINCT \"Fire Name\") AS Total_Fires\n",
    "FROM\n",
    "    fires\n",
    "GROUP BY\n",
    "    County, Year\n",
    "ORDER BY\n",
    "    County, Year;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "fire_counts_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the result\n",
    "print(fire_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cid              name     type  notnull dflt_value  pk\n",
      "0     0  Extracted_County     TEXT        0       None   0\n",
      "1     1            County     TEXT        0       None   0\n",
      "2     2        Tot_Damage     REAL        0       None   0\n",
      "3     3              Year  INTEGER        0       None   0\n",
      "4     4     COUNTY_ABBREV     TEXT        0       None   0\n",
      "5     5       COUNTY_CODE     TEXT        0       None   0\n",
      "6     6       COUNTY_FIPS     TEXT        0       None   0\n",
      "7     7       COUNTY_NAME     TEXT        0       None   0\n",
      "8     8        COUNTY_NUM  INTEGER        0       None   0\n",
      "9     9          GlobalID     TEXT        0       None   0\n",
      "10   10            ISLAND     TEXT        0       None   0\n",
      "11   11       Fire_County     TEXT        0       None   0\n",
      "12   12         Fire Name     TEXT        0       None   0\n",
      "13   13             Start     TEXT        0       None   0\n",
      "14   14         Contained     TEXT        0       None   0\n",
      "15   15             Acres  INTEGER        0       None   0\n",
      "16   16         Deaths_FF  INTEGER        0       None   0\n",
      "17   17      Deaths_Civil  INTEGER        0       None   0\n",
      "18   18          Duration  INTEGER        0       None   0\n",
      "19   19       Strux_Destr  INTEGER        0       None   0\n",
      "20   20        Strux_Dmgd  INTEGER        0       None   0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your SQLite database\n",
    "sqlite_db_path = 'Outputs/DB/fire_data.sqlite'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Query to get the column names of the final_merged_data table\n",
    "query = \"PRAGMA table_info(final_merged_data);\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "columns_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the columns\n",
    "print(columns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fires',), ('extracted',), ('california_county_boundaries',), ('final_merged_data',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your SQLite database\n",
    "sqlite_db_path = 'Outputs/DB/fire_data.sqlite'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Query to list all tables in the database\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "\n",
    "# Execute the query\n",
    "tables = conn.execute(query).fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the tables\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      County  Year  Total_Acres_Burned\n",
      "0    Alameda  2010                 475\n",
      "1    Alameda  2011                1045\n",
      "2    Alameda  2015                2850\n",
      "3    Alameda  2018                 480\n",
      "4    Alameda  2022                 552\n",
      "..       ...   ...                 ...\n",
      "452     Yuba  2011                 360\n",
      "453     Yuba  2016                 389\n",
      "454     Yuba  2017               10939\n",
      "455     Yuba  2020                2411\n",
      "456     Yuba  2021                 939\n",
      "\n",
      "[457 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your SQLite database\n",
    "sqlite_db_path = 'Outputs/DB/fire_data.sqlite'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Define the SQL query to calculate total acres burned\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    County,\n",
    "    Year,\n",
    "    SUM(Acres) AS Total_Acres_Burned\n",
    "FROM\n",
    "    fires\n",
    "GROUP BY\n",
    "    County, Year\n",
    "ORDER BY\n",
    "    County, Year;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "acres_burned_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the result\n",
    "print(acres_burned_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique fire days per county per year have been stored in the 'unique_fire_days' table in your database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/q6dl733j0hdfhxbg883rg3xc0000gn/T/ipykernel_8881/1757942905.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  unique_fire_days = df.groupby(['Year', 'County'], group_keys=False).apply(lambda x: union_active_days(x)).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Path to your SQLite database\n",
    "sqlite_db_path = 'Outputs/DB/fire_data.sqlite'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Load the data from the database into a DataFrame\n",
    "df = pd.read_sql_query(\"SELECT County, Year, Start, Contained FROM fires\", conn)\n",
    "\n",
    "# Convert the 'Start' and 'Contained' columns to datetime\n",
    "df['Start'] = pd.to_datetime(df['Start'])\n",
    "df['Contained'] = pd.to_datetime(df['Contained'])\n",
    "\n",
    "# Function to generate a set of active days for a fire\n",
    "def get_active_days(row):\n",
    "    return pd.date_range(start=row['Start'], end=row['Contained'])\n",
    "\n",
    "# Apply the function to each row to generate the active days\n",
    "df['Active_Days'] = df.apply(get_active_days, axis=1)\n",
    "\n",
    "# Group by 'Year' and 'County' and union all active days, explicitly excluding the grouping columns\n",
    "def union_active_days(group):\n",
    "    all_days = set().union(*group['Active_Days'])\n",
    "    return pd.Series({'Unique_Fire_Days': len(all_days)})\n",
    "\n",
    "# Apply the union function with include_groups=False\n",
    "unique_fire_days = df.groupby(['Year', 'County'], group_keys=False).apply(lambda x: union_active_days(x)).reset_index()\n",
    "\n",
    "# Store the results in the database\n",
    "unique_fire_days.to_sql('unique_fire_days', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Unique fire days per county per year have been stored in the 'unique_fire_days' table in your database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      County  Year  Unique_Fire_Days\n",
      "0    Alameda  2010                 2\n",
      "1    Alameda  2011                 3\n",
      "2    Alameda  2015                 7\n",
      "3    Alameda  2018                 2\n",
      "4    Alameda  2022                 1\n",
      "..       ...   ...               ...\n",
      "452     Yuba  2011                 2\n",
      "453     Yuba  2016                 2\n",
      "454     Yuba  2017                13\n",
      "455     Yuba  2020                 4\n",
      "456     Yuba  2021                 9\n",
      "\n",
      "[457 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your SQLite database\n",
    "sqlite_db_path = 'Outputs/DB/fire_data.sqlite'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Define the SQL query\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    County,\n",
    "    Year,\n",
    "    Unique_Fire_Days\n",
    "FROM\n",
    "    unique_fire_days\n",
    "ORDER BY\n",
    "    County, Year;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "unique_fire_days_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the result\n",
    "print(unique_fire_days_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the columns in the shapefile\n",
    "print(\"Columns in counties_gdf:\", counties_gdf.columns)\n",
    "\n",
    "# Check the columns in the database query result\n",
    "print(\"Columns in data:\", data.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boot_camp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
